{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to\n",
    "{{ badge }}\n",
    "\n",
    "Gradio is a powerful, open-source library for building user interfaces (UI) in Python. It allows developers to easily create web-based interfaces for machine learning models, data visualization, and other Python scripts. With Gradio, you can easily share your work with a wider audience and make your models accessible to non-technical users.\n",
    "\n",
    "Here are some of the key features of Gradio:\n",
    "- **Easy to use**: Gradio has a simple and intuitive API that makes it easy to get started.\n",
    "- **Built-in support for popular ML libraries**: Gradio has built-in support for popular ML libraries like TensorFlow, Keras, and PyTorch, allowing you to easily deploy your models.\n",
    "- **Customizable**: Gradio provides options for adding custom HTML, JavaScript, and CSS to the interface, allowing you to customize the look and feel of your application.\n",
    "- **Advanced features**: Gradio provides advanced features such as authentication and access control, logging, monitoring, and more.\n",
    "\n",
    "You can easily install Gradio using `pip` and start building your interface with as little as few lines of code. The library is well-documented and there are plenty of resources and tutorials available to help you get started.\n",
    "\n",
    "For more information, you can check out the [official documentation](https://gradio.app/docs) and the [GitHub repository](https://github.com/gradio-app/gradio)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table of Contents <a name=\"toc\"></a>\n",
    "* [Concepts](#concepts)\n",
    "* [Components](#components)\n",
    "* [Code Examples](#code-examples)\n",
    "    * [Greetings](#greetings)\n",
    "    * [Calculator](#calculator)\n",
    "    * [MNIST Classifier](#mnist-classifier)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concepts <a name=\"concepts\"></a>\n",
    "\n",
    "- **Interfaces**: In Gradio, an interface is a web-based UI that allows users to interact with a machine learning model or other Python script. An interface can be built using the `gr.Interface` class and can consist of inputs, outputs, and custom HTML, JavaScript and CSS.\n",
    "\n",
    "- **Run function**: The run function is a python function that takes the inputs as inputs and returns the outputs. It is the backbone of the interface, it is the function that will be executed when the user interacts with the interface.\n",
    "\n",
    "- **Inputs**: An input is a parameter that the user can interact with to generate the output. For example, an image classifier would have an input of an image. In Gradio, inputs can be created using the `gr.inputs` function.\n",
    "\n",
    "- **Outputs**: An output is the result generated by the model or script based on the inputs. In Gradio, outputs can be created using the `gr.outputs` function.\n",
    "\n",
    "- **Customization**: Gradio provides options for customizing the look and feel of the interface using HTML, CSS and JavaScript. Additionally, it also provides options for customizing the functionality and behavior of the interface.\n",
    "\n",
    "- **Launching**: Once the interface is created, it can be launched by calling the `launch()` function on the interface object. This will open the interface in a new browser tab.\n",
    "\n",
    "- **Sharing**:  Once the interface is launched, it can be shared with others via a shareable link. This allows others to use the interface without having to run the code locally."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Components <a name=\"components\"></a>\n",
    "\n",
    "Gradio has built-in support for several types of inputs and outputs, which can be used to create a wide range of interfaces, some of the most common ones are listed below:\n",
    "\n",
    "### Inputs\n",
    "- **Textbox**: Accepts a single line of text input from the user. Can be customized with options such as `label`, `placeholder`, `default`.\n",
    "- **Checkbox**: Accepts a boolean input from the user. Can be customized with options such as `label`, `default`.\n",
    "- **Radio**: Accepts one option from a set of options provided by the user. Can be customized with options such as `label`, `options`, `default`.\n",
    "- **Select**: Accepts one option from a set of options provided by the user. Can be customized with options such as `label`, `options`, `default`.\n",
    "- **Slider**: Accepts a numeric input from the user within a range provided by the user. Can be customized with options such as `label`, `min`, `max`, `step`, `default`.\n",
    "- **File**: Accepts a file input from the user. Can be customized with options such as `label`, `allowed_extensions`.\n",
    "- **Image**: Accepts an image input from the user. Can be customized with options such as `shape`, `label`.\n",
    "\n",
    "### Outputs\n",
    "- **Textbox**: Displays a single line of text. Can be customized with options such as `label`.\n",
    "- **Label**: Displays probability scores for a set of classes. Can be customized with options such as `label`, `num_top_classes`.\n",
    "- **Plot**: Displays a plot. Can be customized with options such as `label`.\n",
    "- **Chatbot**: Displays a chatbot interface. Can be customized with options such as `label`.\n",
    "\n",
    "\n",
    "All of these components can be easily used by importing them from the `gradio.inputs` and `gradio.outputs` modules. For more information, you can check out the [official documentation](https://gradio.app/docs/#components)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code Examples <a name=\"code-examples\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As of writing this tutorial, Gradio is not available by default on Google Colab and needs to be installed manually, to install it run this cell\n",
    "!pip install gradio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gradio as gr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Greetings <a name=\"greetings\"></a>\n",
    "A simple interface that takes a name as input and returns a greeting as output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def greeting(name):\n",
    "  return f\"Hello {name}!\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=greeting,\n",
    "    inputs= gr.inputs.Textbox(label=\"Your Name\", placeholder=\"Enter your name here\"),\n",
    "    outputs= gr.inputs.Textbox(label=\"Greeting\")\n",
    ")\n",
    "\n",
    "interface.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculator <a name=\"calculator\"></a>\n",
    "A simple interface that takes two numbers and operation as input and returns the result as output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def calculate(num1, num2, op):\n",
    "\n",
    "  output = \"\"\n",
    "\n",
    "  if op == \"+\":\n",
    "    output = num1 + num2\n",
    "  elif op == \"-\":\n",
    "    output = num1 - num2\n",
    "  elif op == \"*\":\n",
    "    output = num1 * num2\n",
    "  elif op == \"/\":\n",
    "    if num2 != 0:\n",
    "      output = num1 / num2\n",
    "    else:\n",
    "      output = \"Division by zero is not allowed\"\n",
    "  else:\n",
    "    output = \"Unsupported operation\"\n",
    "\n",
    "  return output\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=calculate,\n",
    "    inputs= [\n",
    "        gr.inputs.Number(label=\"Number 1\"),\n",
    "        gr.inputs.Number(label=\"Number 2\"),\n",
    "        gr.inputs.Radio(choices=[\"+\",\"-\", \"*\", \"/\"], label=\"Choose the Operation\", default=\"+\"),\n",
    "    ],\n",
    "    outputs= gr.inputs.Textbox(),\n",
    "    title=\"Super Awesome Calculator\",\n",
    "    description=\"This calculator takes in any two numbers and does all four major operations on them, isn't that awesome?!\",\n",
    "    live=True\n",
    ")\n",
    "\n",
    "interface.launch(debug=True, share=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MNIST Classifier <a name=\"mnist-classifier\"></a>\n",
    "A simple interface that takes an image as input and returns the predicted digit as output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "((60000, 28, 28), (60000,), (10000, 28, 28), (60000,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a random image index\n",
    "index = np.random.randint(0, x_train.shape[0])\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(x_train[index], cmap='gray')\n",
    "plt.title(\"Label: \" + str(y_train[index]))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 784), (10000, 784))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the data to be in the format (batch_size, input_dim) because Dense layers require one dimensional input\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "x_train.shape, x_test.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert the labels from integers to categorical using one hot encoding\n",
    "depth = len(set(y_train)) # calculate the number of classes to use as depth\n",
    "y_train = tf.one_hot(y_train, depth=depth)\n",
    "y_test = tf.one_hot(y_test, depth=depth)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fetch the input shape, i.e. the number of features\n",
    "input_shape = x_train.shape[1] # input_shape = 784\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # input layer\n",
    "    tf.keras.layers.Input(shape=(input_shape)),\n",
    "    # hidden layers\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    # output layer\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 276us/sample - loss: 0.2821 - categorical_accuracy: 0.9145 - val_loss: 0.1135 - val_categorical_accuracy: 0.9662\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.1299 - categorical_accuracy: 0.9617 - val_loss: 0.0804 - val_categorical_accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 316us/sample - loss: 0.1010 - categorical_accuracy: 0.9691 - val_loss: 0.0844 - val_categorical_accuracy: 0.9734\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 21s 348us/sample - loss: 0.0812 - categorical_accuracy: 0.9749 - val_loss: 0.0772 - val_categorical_accuracy: 0.9777\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s 326us/sample - loss: 0.0708 - categorical_accuracy: 0.9788 - val_loss: 0.0674 - val_categorical_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 19s 318us/sample - loss: 0.0655 - categorical_accuracy: 0.9799 - val_loss: 0.0758 - val_categorical_accuracy: 0.9784\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 281us/sample - loss: 0.0586 - categorical_accuracy: 0.9810 - val_loss: 0.0714 - val_categorical_accuracy: 0.9806\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0519 - categorical_accuracy: 0.9840 - val_loss: 0.0733 - val_categorical_accuracy: 0.9804\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0486 - categorical_accuracy: 0.9841 - val_loss: 0.0742 - val_categorical_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 19s 314us/sample - loss: 0.0468 - categorical_accuracy: 0.9853 - val_loss: 0.0765 - val_categorical_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7faa8e822610>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Interface #1\n",
    "This interface takes an image as input and returns the predicted digit as output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_mnist(img):\n",
    "    # check if no image is passed\n",
    "    if img is None:\n",
    "        return \"You didn't pass an image\"\n",
    "\n",
    "    # reduce the three color channel to single grayscale value\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    # reshape/flatten the image\n",
    "    img = tf.reshape(img, (1, 28 * 28))\n",
    "    # cast tensor values to float32\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # normalize pixel values between 0 and 1\n",
    "    img = img / 255.0\n",
    "\n",
    "    # getting the predictions of the model\n",
    "    prediction = model.predict(img)\n",
    "    prediction = prediction[0]\n",
    "    # getting the index of the highest probability\n",
    "    index = tf.argmax(prediction)\n",
    "\n",
    "    return int(index)\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    # function that will be called when the user inputs an image\n",
    "    fn=predict_mnist,\n",
    "    # the input the user will use to interact with the function\n",
    "    inputs=gr.inputs.Image(shape=(28, 28)),\n",
    "    # the output the user will see after interacting with the function\n",
    "    outputs=gr.inputs.Textbox(label=\"Predicted Digit\"),\n",
    "    # title of the interface\n",
    "    title=\"Hand-written digits recognizer\",\n",
    "    # description of the interface\n",
    "    description=\"Neural network to accurately predict a hand-written digit based on an image\",\n",
    ")\n",
    "# launch the interface and allow sharing\n",
    "interface.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Interface #2\n",
    "This interface takes an image as input and returns the predicted digit as output. It also shows the probability of each digit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_mnist(img):\n",
    "    # check if no image is passed\n",
    "    if img is None:\n",
    "        return \"You didn't pass an image\"\n",
    "\n",
    "    # reduce the three color channel to single grayscale value\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    # reshape/flatten the image\n",
    "    img = tf.reshape(img, (1, 28 * 28))\n",
    "    # cast tensor values to float32\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # normalize pixel values between 0 and 1\n",
    "    img = img / 255.0\n",
    "\n",
    "    # getting the predictions of the model\n",
    "    prediction = model.predict(img)\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    for i in range(len(prediction)): # loop through all the predictions\n",
    "        labels[f\"{i}\"] = float(prediction[i]) # add the prediction to the dictionary\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    # function that will be called when the user inputs an image\n",
    "    fn=predict_mnist,\n",
    "    # the input the user will use to interact with the function\n",
    "    inputs=gr.inputs.Image(shape=(28, 28)),\n",
    "    # the output the user will see after interacting with the function\n",
    "    outputs=gr.outputs.Label(label=\"Predicted Digit\", num_top_classes=3),\n",
    "    # title of the interface\n",
    "    title=\"Hand-written digits recognizer\",\n",
    "    # description of the interface\n",
    "    description=\"Neural network to accuratly predict a hand-written digit based on an image\",\n",
    "    # options for flagging\n",
    "    flagging_options=[\"Incorrect Prediction\", \"Program Error\"],\n",
    "    # directory to store flags in, if not specified, flags will be stored in a folder called flags in the current directory\n",
    "    # it's a good idea to specify a different directory for each interface\n",
    "    flagging_dir=\"mnist_experiment_2\"\n",
    ")\n",
    "# launch the interface and allow sharing\n",
    "interface.launch(share=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}